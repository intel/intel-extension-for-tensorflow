<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Advanced Auto Mixed Precision &mdash; Intel® Extension for TensorFlow* 0.1.dev1+gfae9dae documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=439db15d" />

  
<script type="text/javascript">
  // Configure TMS settings
  window.wapProfile = 'profile-microsite'; // This is mapped by WAP authorize value
  window.wapLocalCode = 'us-en'; // Dynamically set per localized site, see mapping table for values
  window.wapSection = "intel-extension-for-tensorflow"; // WAP team will give you a unique section for your site
  window.wapEnv = 'prod'; // environment to be use in Adobe Tags.
  // Load TMS
  (() => {
        let url = 'https://www.intel.com/content/dam/www/global/wap/main/wap-microsite.js';
        let po = document.createElement('script'); po.type = 'text/javascript'; po.async = true; po.src = url;
        let s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  }) ();
</script>

    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Python APIs" href="python_api.html" />
    <link rel="prev" title="Graph fusion" href="itex_fusion.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Intel® Extension for TensorFlow*
          </a>
            <div class="version">
              <a href="../../../versions.html">latest▼</a>
              <p>Click link above to switch version</p>
            </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../get_started.html">Intel® Extension for TensorFlow*</a></li>
<li class="toctree-l1"><a class="reference internal" href="infrastructure.html">Infrastructure</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="features.html">Features</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="features.html#operator-optimization">Operator Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="features.html#graph-optimization">Graph Optimization</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="features.html#advanced-auto-mixed-precision-amp">Advanced Auto Mixed Precision (AMP)</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Advanced Auto Mixed Precision</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id1">Advanced Auto Mixed Precision</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#advanced-amp-vs-stock-tensorflow-amp">Advanced AMP vs. Stock TensorFlow AMP</a></li>
<li class="toctree-l5"><a class="reference internal" href="#data-type">Data Type</a></li>
<li class="toctree-l5"><a class="reference internal" href="#graph-optimizer">Graph Optimizer</a></li>
<li class="toctree-l5"><a class="reference internal" href="#feature">Feature</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#tune-advanced-amp-manually">Tune Advanced AMP Manually</a></li>
<li class="toctree-l4"><a class="reference internal" href="#usage">Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="#example">Example</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#quick-training-example">Quick Training Example</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#setup">Setup</a></li>
<li class="toctree-l6"><a class="reference internal" href="#enable-advanced-amp">Enable Advanced AMP</a></li>
<li class="toctree-l6"><a class="reference internal" href="#original-code">Original Code</a></li>
<li class="toctree-l6"><a class="reference internal" href="#notice">Notice</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#tips">Tips</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#log-and-save-optimized-graph">Log and Save Optimized Graph</a></li>
<li class="toctree-l5"><a class="reference internal" href="#custom-operation">Custom Operation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features.html#ease-of-use-python-api">Ease-of-use Python API</a></li>
<li class="toctree-l2"><a class="reference internal" href="features.html#gpu-profiler">GPU Profiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="features.html#cpu-launcher-experimental">CPU Launcher [Experimental]</a></li>
<li class="toctree-l2"><a class="reference internal" href="features.html#int8-quantization">INT8 Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="features.html#xpuautoshard-on-gpu-experimental">XPUAutoShard on GPU [Experimental]</a></li>
<li class="toctree-l2"><a class="reference internal" href="features.html#openxla-support-on-gpu-experimental">OpenXLA Support on GPU [Experimental]</a></li>
<li class="toctree-l2"><a class="reference internal" href="features.html#tensorflow-serving">TensorFlow Serving</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="performance.html">Performance Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install/installation_guide.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/README.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="practice_guide.html">Practice Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/contributing.html">Contributing guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../SECURITY.html">Security Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/intel-extension-for-tensorflow">GitHub Repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Intel® Extension for TensorFlow*</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="features.html">Features</a></li>
      <li class="breadcrumb-item active">Advanced Auto Mixed Precision</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/docs/guide/advanced_auto_mixed_precision.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="advanced-auto-mixed-precision">
<h1>Advanced Auto Mixed Precision<a class="headerlink" href="#advanced-auto-mixed-precision" title="Link to this heading"></a></h1>
<p>Mixed Precision uses lower-precision data types (such as FP16 or BF16) to make models run faster with less memory consumption during training and inference.</p>
<p>Stock TensorFlow provides two ways to do this, Grappler Graph Optimization <a class="reference external" href="https://www.tensorflow.org/guide/graph_optimization">Auto Mixed Precision</a> <strong>(AMP)</strong> and <a class="reference external" href="https://www.tensorflow.org/guide/mixed_precision">Keras mixed precision API</a>.</p>
<p>Intel® Extension for TensorFlow* is fully compatible with Keras mixed precision API in Stock TensorFlow, and provides an <strong>Advanced Auto Mixed Precision</strong> feature for better performance.</p>
<ul class="simple">
<li><p><a class="reference external" href="#overview">Overview</a></p></li>
<li><p><a class="reference external" href="#advanced-auto-mixed-precision">Advanced Auto Mixed Precision</a></p></li>
<li><p><a class="reference external" href="#tune-advanced-amp-manually">Tune Advanced AMP Manually</a></p></li>
<li><p><a class="reference external" href="#usage">Usage</a></p></li>
<li><p><a class="reference external" href="#example">Example</a></p></li>
<li><p><a class="reference external" href="#tips">Tips</a></p></li>
</ul>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading"></a></h2>
<p>Intel® Extension for TensorFlow* provides two ways to support mixed precision:</p>
<p>I. Keras Mixed Precision</p>
<p>Intel® Extension for TensorFlow* is fully compatible with Keras mixed precision API available in Stock TensorFlow. To learn about Keras mixed precision, refer to <a class="reference external" href="/docs/guide/keras_mixed_precision.html">Keras Mixed Precision</a>.</p>
<p>II. Advanced Auto Mixed Precision</p>
<p>Advanced Auto Mixed Precision (Advanced AMP) is similar to stock TensorFlow Auto Mixed Precision, but it offers better usage and performance on Intel CPU and GPU.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Feature</th>
<th>Keras Mixed Precision API</th>
<th>Advanced Auto Mixed Precision</th>
</tr>
</thead>
<tbody>
<tr>
<td>Python Model</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Frozen Graph (PB) model</td>
<td></td>
<td>Yes</td>
</tr>
<tr>
<td>Based on Operation Type</td>
<td></td>
<td>Yes</td>
</tr>
<tr>
<td>Based on Operation Name</td>
<td>Yes</td>
<td></td>
</tr>
</tbody>
</table></section>
<section id="id1">
<h2>Advanced Auto Mixed Precision<a class="headerlink" href="#id1" title="Link to this heading"></a></h2>
<section id="advanced-amp-vs-stock-tensorflow-amp">
<h3>Advanced AMP vs. Stock TensorFlow AMP<a class="headerlink" href="#advanced-amp-vs-stock-tensorflow-amp" title="Link to this heading"></a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th></th>
<th>Advanced AMP</th>
<th>Stock TensorFlow AMP</th>
</tr>
</thead>
<tbody>
<tr>
<td>Intel CPU</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Intel GPU</td>
<td>Yes</td>
<td></td>
</tr>
<tr>
<td>Custom operations provided by Intel® Extension for TensorFlow*<br> such as LayerNorm, InstanceNorm and Swish</td>
<td>Yes</td>
<td></td>
</tr>
<tr>
<td>Python API</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Environment Variable API</td>
<td>Yes</td>
<td>Yes</td>
</tr>
</tbody>
</table></section>
<section id="data-type">
<h3>Data Type<a class="headerlink" href="#data-type" title="Link to this heading"></a></h3>
<p>Advanced Auto Mixed Precision supports data type depended on hardware:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th></th>
<th>FP16</th>
<th>BF16</th>
</tr>
</thead>
<tbody>
<tr>
<td>Intel CPU</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Intel GPU</td>
<td>Yes</td>
<td>Yes</td>
</tr>
</tbody>
</table></section>
<section id="graph-optimizer">
<h3>Graph Optimizer<a class="headerlink" href="#graph-optimizer" title="Link to this heading"></a></h3>
<p>Intel® Extension for TensorFlow* graph optimizer provides more powerful optimization for mixed precision graph versus a stock TensorFlow custom graph optimizer.</p>
<p>I. After Advanced AMP of Intel® Extension for TensorFlow* is enabled, the stock TensorFlow AMP components: AMP and Remapper will be disabled automatically.</p>
<p>II. Intel® Extension for TensorFlow* AMP and Remapper work for mixed precision. The order is changed to Remapper, then AMP, so that fusion operations can be mixed precision.</p>
<p>III. Intel® Extension for TensorFlow* implements some existing operations to cover those in stock TensorFlow, for better performance in Intel hardware.</p>
<p>IV. Intel® Extension for TensorFlow* implements custom operations.</p>
<p><img alt="workflow.png" src="../../_images/workflow.png" /></p>
</section>
<section id="feature">
<h3>Feature<a class="headerlink" href="#feature" title="Link to this heading"></a></h3>
<p>Advanced AMP based on Intel® Extension for TensorFlow* has more features to improve performance than stock TensorFlow AMP:</p>
<ul class="simple">
<li><p>Provides more aggressive sub-graph fusion, such as LayerNorm and InstanceNorm fusion.</p></li>
<li><p>Supports mixed precision in fused Operations, which are not supported by stock TensorFlow.</p></li>
</ul>
</section>
</section>
<section id="tune-advanced-amp-manually">
<h2>Tune Advanced AMP Manually<a class="headerlink" href="#tune-advanced-amp-manually" title="Link to this heading"></a></h2>
<p>In most cases, with default configuration, Advanced AMP delivers good results with balanced performance and accuracy.
For advanced users with more knowledge of model and TensorFlow, it is possible to manually tune Advanced AMP for special cases or custom operations.</p>
<p>Refer to <a class="reference external" href="aamp_tune.html">Tune Advanced Auto Mixed Precision</a> for advanced operations.</p>
</section>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Link to this heading"></a></h2>
<p>I. Install Intel® Extension for TensorFlow* in running environment.</p>
<p>After Installing Intel® Extension for TensorFlow*, it will automatically activate as a plugin of stock TensorFlow.</p>
<p>Refer to <a class="reference external" href="../../get_started.html##Install">installation</a> instructions for more details.</p>
<p>II. Enable Advanced AMP.</p>
<p>With the default configuration, the Advanced AMP has a good balance between performance and accuracy in most cases.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th></th>
<th>Python API</th>
<th>Environment Variable</th>
</tr>
</thead>
<tbody>
<tr>
<td>Basic (Default configuration)</td>
<td><code>import intel_extension_for_tensorflow as itex</code><br><br><code>auto_mixed_precision_options = itex.AutoMixedPrecisionOptions()</code><br><code>auto_mixed_precision_options.data_type = itex.BFLOAT16 #itex.FLOAT16</code><br><br><code>graph_options = itex.GraphOptions(auto_mixed_precision_options=auto_mixed_precision_options)</code><br><code>graph_options.auto_mixed_precision = itex.ON</code><br><br><code>config = itex.ConfigProto(graph_options=graph_options)</code><br><code>itex.set_config(config)</code></td>
<td><code>export ITEX_AUTO_MIXED_PRECISION=1</code><br><code>export ITEX_AUTO_MIXED_PRECISION_DATA_TYPE="BFLOAT16" #"FLOAT16"</code><br></td>
</tr>
</tbody>
</table><p>III. Use the Python API or environment variables to manually tune Advanced AMP for better performance, accuracy, or both.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th></th>
<th>Python API</th>
<th>Environment Variable</th>
</tr>
</thead>
<tbody>
<tr>
<td>Advanced Configuration</td>
<td><code>auto_mixed_precision_options.allowlist_add= "AvgPool3D,AvgPool"</code><br><code>auto_mixed_precision_options.inferlist_remove = "AvgPool3D,AvgPool"</code></td>
<td><code>export ITEX_AUTO_MIXED_PRECISION_ALLOWLIST_ADD="AvgPool3D,AvgPool"</code><br><code>export ITEX_AUTO_MIXED_PRECISION_INFERLIST_REMOVE="AvgPool3D,AvgPool"</code></td>
</tr>
</tbody>
</table><p>Refer to <a class="reference external" href="aamp_tune.html#usage">Usage</a></p>
</section>
<section id="example">
<h2>Example<a class="headerlink" href="#example" title="Link to this heading"></a></h2>
<section id="quick-training-example">
<h3>Quick Training Example<a class="headerlink" href="#quick-training-example" title="Link to this heading"></a></h3>
<p>Train model for BF16 with Advanced AMP on GPU device.</p>
<section id="setup">
<h4>Setup<a class="headerlink" href="#setup" title="Link to this heading"></a></h4>
<p>Install Intel® Extension for TensorFlow*, refer to <a class="reference external" href="../../get_started.html##Install">installation</a>.</p>
</section>
<section id="enable-advanced-amp">
<h4>Enable Advanced AMP<a class="headerlink" href="#enable-advanced-amp" title="Link to this heading"></a></h4>
<p>Use either the Python API or the environment variables to enable Advanced AMP.</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Python API</th>
<th>Environment Variable</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>import intel_extension_for_tensorflow as itex</code><br><br><code>auto_mixed_precision_options = itex.AutoMixedPrecisionOptions()</code><br><code>auto_mixed_precision_options.data_type = itex.BFLOAT16</code><br><br><code>graph_options = itex.GraphOptions(auto_mixed_precision_options=auto_mixed_precision_options)</code><br><code>graph_options.auto_mixed_precision = itex.ON</code><br><br><code>config = itex.ConfigProto(graph_options=graph_options)</code><br><code>itex.set_config(config)</code></td>
<td><code>export ITEX_AUTO_MIXED_PRECISION=1</code><br><code>export ITEX_AUTO_MIXED_PRECISION_DATA_TYPE="BFLOAT16"</code><br></td>
</tr>
</tbody>
</table></section>
<section id="original-code">
<h4>Original Code<a class="headerlink" href="#original-code" title="Link to this heading"></a></h4>
<p>Insert the Python API above in the original code, or set environment variables above before executing the original code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>


<span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;XPU&#39;</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The model will run with 4096 units on an XPU&#39;</span><span class="p">)</span>
  <span class="n">num_units</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="k">else</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The model will run with 64 units on a CPU&#39;</span><span class="p">)</span>
  <span class="n">num_units</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;digits&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense_1&#39;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense_2&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense_logits&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">8192</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">test_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test loss:&#39;</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test accuracy:&#39;</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="notice">
<h4>Notice<a class="headerlink" href="#notice" title="Link to this heading"></a></h4>
<p>The first epoch may be slower because TensorFlow optimizes the model during the first run. In subsequent epochs, the time will stabilize.</p>
</section>
</section>
</section>
<section id="tips">
<h2>Tips<a class="headerlink" href="#tips" title="Link to this heading"></a></h2>
<section id="log-and-save-optimized-graph">
<h3>Log and Save Optimized Graph<a class="headerlink" href="#log-and-save-optimized-graph" title="Link to this heading"></a></h3>
<p>Advanced AMP supports outputting the log and optimized graph by setting an environment variable:</p>
<p><code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">ITEX_AUTO_MIXED_PRECISION_LOG_PATH=&quot;/my/path/&quot;</span></code></p>
<p>It will trigger Intel® Extension for TensorFlow* to save the post optimization graph and detailed conversion log to a local folder.</p>
<p>Use this to check the structure of the final graph to learn the mixed precision status. It also helps to know the rules to convert operations from FP32 to BF16.</p>
<p>For detailed introduction, refer to <a class="reference external" href="aamp_tune.html#tuning-performance-example-by-advanced-amp-configure-list-manually">Tuning Performance Example by Advanced AMP Configure List Manually</a></p>
</section>
<section id="custom-operation">
<h3>Custom Operation<a class="headerlink" href="#custom-operation" title="Link to this heading"></a></h3>
<p>When writing a custom operation, add it to the configuration list to enable Advanced AMP.</p>
<p>Refer to <a class="reference external" href="aamp_tune.html#tune-advanced-auto-mixed-precision">Tune Advanced Auto Mixed Precision</a> for more details.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="itex_fusion.html" class="btn btn-neutral float-left" title="Graph fusion" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="python_api.html" class="btn btn-neutral float-right" title="Python APIs" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022-2024 Intel Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   <jinja2.runtime.BlockReference object at 0x7f472f554340> 
  <p></p><div><a href='https://www.intel.com/content/www/us/en/privacy/intel-cookie-notice.html' data-cookie-notice='true'>Cookies</a> <a href='https://www.intel.com/content/www/us/en/privacy/intel-privacy-notice.html'>| Privacy</a></div>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>