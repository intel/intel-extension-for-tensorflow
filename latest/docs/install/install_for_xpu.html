<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Intel XPU Software Installation &mdash; Intel® Extension for TensorFlow* 0.1.dev1+gc71ec32 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=439db15d" />

  
<script type="text/javascript">
  // Configure TMS settings
  window.wapProfile = 'profile-microsite'; // This is mapped by WAP authorize value
  window.wapLocalCode = 'us-en'; // Dynamically set per localized site, see mapping table for values
  window.wapSection = "intel-extension-for-tensorflow"; // WAP team will give you a unique section for your site
  window.wapEnv = 'prod'; // environment to be use in Adobe Tags.
  // Load TMS
  (() => {
        let url = 'https://www.intel.com/content/dam/www/global/wap/main/wap-microsite.js';
        let po = document.createElement('script'); po.type = 'text/javascript'; po.async = true; po.src = url;
        let s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  }) ();
</script>

    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Intel CPU Software Installation" href="install_for_cpu.html" />
    <link rel="prev" title="Installation Guide" href="installation_guide.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            Intel® Extension for TensorFlow*
          </a>
            <div class="version">
              <a href="../../../versions.html">latest▼</a>
              <p>Click link above to switch version</p>
            </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../get_started.html">Intel® Extension for TensorFlow*</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/infrastructure.html">Infrastructure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/features.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/performance.html">Performance Data</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="installation_guide.html">Installation Guide</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Intel XPU Software Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#hardware-requirements">Hardware Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#software-requirements">Software Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#install-gpu-drivers">Install GPU Drivers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#install-via-docker-container">Install via Docker container</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#build-docker-container-from-dockerfile">Build Docker container from Dockerfile</a></li>
<li class="toctree-l4"><a class="reference internal" href="#get-docker-container-from-dockerhub">Get docker container from dockerhub</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#install-via-pypi-wheel-in-bare-metal">Install via PyPI wheel in bare metal</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#install-oneapi-base-toolkit-packages">Install oneAPI Base Toolkit Packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="#setup-environment-variables">Setup environment variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="#install-tensorflow">Install TensorFlow</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#virtual-environment-install">Virtual environment install</a></li>
<li class="toctree-l5"><a class="reference internal" href="#system-environment-install">System environment install</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#install-intel-extension-for-tensorflow">Install Intel® Extension for TensorFlow*</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#check-the-environment-for-xpu">Check the Environment for XPU</a></li>
<li class="toctree-l5"><a class="reference internal" href="#verify-the-installation">Verify the Installation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#xpu-for-cpu-only-platform-deprecated">XPU for CPU only platform (Deprecated)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="install_for_cpu.html">Intel CPU Software Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="experimental/install_for_gpu_conda.html">Conda Environment Installation Instructions</a></li>
<li class="toctree-l2"><a class="reference internal" href="how_to_build.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="how_to_build.html#requirements">Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="how_to_build.html#build-intel-extension-for-tensorflow-pypi">Build Intel® Extension for TensorFlow* PyPI</a></li>
<li class="toctree-l2"><a class="reference internal" href="how_to_build.html#additional">Additional</a></li>
<li class="toctree-l2"><a class="reference internal" href="install_for_cpp.html">Intel® Extension for TensorFlow* for C++</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/README.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/practice_guide.html">Practice Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/FAQ.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/contributing.html">Contributing guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../SECURITY.html">Security Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/intel-extension-for-tensorflow">GitHub Repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Intel® Extension for TensorFlow*</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="installation_guide.html">Installation Guide</a></li>
      <li class="breadcrumb-item active">Intel XPU Software Installation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/docs/install/install_for_xpu.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="intel-xpu-software-installation">
<h1>Intel XPU Software Installation<a class="headerlink" href="#intel-xpu-software-installation" title="Link to this heading"></a></h1>
<p>This guide shows how to use an Intel® Extension for TensorFlow* XPU package, which provides GPU and CPU support simultaneously.</p>
<section id="hardware-requirements">
<h2>Hardware Requirements<a class="headerlink" href="#hardware-requirements" title="Link to this heading"></a></h2>
<p>Verified Hardware Platforms:</p>
<ul class="simple">
<li><p>Intel® Data Center GPU Max Series, Driver Version: <a class="reference external" href="https://dgpu-docs.intel.com/releases/LTS_803.63_20240617.html">803</a></p></li>
<li><p>Intel® Data Center GPU Flex Series 170, Driver Version: <a class="reference external" href="https://dgpu-docs.intel.com/releases/LTS_803.63_20240617.html">803</a></p></li>
<li><p><em>Experimental:</em> Intel® Arc™ A-Series</p></li>
</ul>
<p>For experimental support of the Intel® Arc™ A-Series GPUs, please refer to <a class="reference external" href="experimental/install_for_arc_gpu.html">Intel® Arc™ A-Series GPU Software Installation</a> for details.</p>
</section>
<section id="software-requirements">
<h2>Software Requirements<a class="headerlink" href="#software-requirements" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p>Ubuntu 22.04, Red Hat 8.6 (64-bit)</p>
<ul>
<li><p>Intel® Data Center GPU Flex Series</p></li>
</ul>
</li>
<li><p>Ubuntu 22.04, Red Hat 8.6 (64-bit), SUSE Linux Enterprise Server(SLES) 15 SP4/SP5</p>
<ul>
<li><p>Intel® Data Center GPU Max Series</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://www.intel.com/content/www/us/en/developer/articles/release-notes/intel-oneapi-toolkit-release-notes.html">Intel® oneAPI Base Toolkit 2024.2.1</a></p></li>
<li><p>TensorFlow 2.15.0</p></li>
<li><p>Python 3.9-3.11</p></li>
<li><p>pip 19.0 or later (requires manylinux2014 support)</p></li>
</ul>
</section>
<section id="install-gpu-drivers">
<h2>Install GPU Drivers<a class="headerlink" href="#install-gpu-drivers" title="Link to this heading"></a></h2>
<table border="1" class="docutils">
<thead>
<tr>
<th>OS</th>
<th>Intel GPU</th>
<th>Install Intel GPU Driver</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ubuntu 22.04, Red Hat 8.6</td>
<td>Intel® Data Center GPU Flex Series</td>
<td>Refer to the <a href="https://dgpu-docs.intel.com/installation-guides/index.html#intel-data-center-gpu-flex-series">Installation Guides</a> for latest driver installation. If install the verified Intel® Data Center GPU Max Series/Intel® Data Center GPU Flex Series <a href="https://dgpu-docs.intel.com/releases/LTS_803.63_20240617.html">803</a>, please append the specific version after components, such as <code>sudo apt-get install intel-opencl-icd==23.43.27642.52-803~22.04</code></td>
</tr>
<tr>
<td>Ubuntu 22.04, Red Hat 8.6, SLES 15 SP4/SP5</td>
<td>Intel® Data Center GPU Max Series</td>
<td>Refer to the <a href="https://dgpu-docs.intel.com/installation-guides/index.html#intel-data-center-gpu-max-series">Installation Guides</a> for latest driver installation. If install the verified Intel® Data Center GPU Max Series/Intel® Data Center GPU Flex Series <a href="https://dgpu-docs.intel.com/releases/LTS_803.63_20240617.html">803</a>, please append the specific version after components, such as <code>sudo apt-get install intel-opencl-icd==23.43.27642.52-803~22.04</code></td>
</tr>
</tbody>
</table></section>
<section id="install-via-docker-container">
<h2>Install via Docker container<a class="headerlink" href="#install-via-docker-container" title="Link to this heading"></a></h2>
<p>The Docker container includes the Intel® oneAPI Base Toolkit, and all other software stack except Intel GPU Drivers. Install the GPU driver in host machine bare metal environment, and then launch the docker container directly.</p>
<section id="build-docker-container-from-dockerfile">
<h3>Build Docker container from Dockerfile<a class="headerlink" href="#build-docker-container-from-dockerfile" title="Link to this heading"></a></h3>
<p>Run the following <a class="reference external" href="./../../docker/README.html">Dockerfile build procedure</a> to build the pip based deployment container.</p>
</section>
<section id="get-docker-container-from-dockerhub">
<h3>Get docker container from dockerhub<a class="headerlink" href="#get-docker-container-from-dockerhub" title="Link to this heading"></a></h3>
<p>Pre-built docker images are available at <a class="reference external" href="https://hub.docker.com/r/intel/intel-extension-for-tensorflow/tags">DockerHub</a>.
Run the following command to pull Intel® Extension for TensorFlow* Docker container image (<code class="docutils literal notranslate"><span class="pre">xpu</span></code>) to your local machine.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ docker pull intel/intel-extension-for-tensorflow:xpu
$ docker run -it -p 8888:8888 --device /dev/dri -v /dev/dri/by-path:/dev/dri/by-path intel/intel-extension-for-tensorflow:xpu
</pre></div>
</div>
<p>To use Intel® Optimization for Horovod* with the Intel® oneAPI Collective Communications Library (oneCCL), pull Intel® Extension for TensorFlow* Docker container image (<code class="docutils literal notranslate"><span class="pre">xpu</span></code>) to your local machine and use the script to set the required environment variables after creating the container by the following command. You can also get the script via <a class="reference external" href="../../docker/horovod-vars.sh">horovod-vars.sh</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ docker pull intel/intel-extension-for-tensorflow:xpu
$ docker run -it -p 8888:8888 --device /dev/dri -v /dev/dri/by-path:/dev/dri/by-path --ipc=host intel/intel-extension-for-tensorflow:xpu
$ source /opt/intel/horovod-vars.sh
</pre></div>
</div>
<p>Then go to your browser on http://localhost:8888/</p>
</section>
</section>
<section id="install-via-pypi-wheel-in-bare-metal">
<h2>Install via PyPI wheel in bare metal<a class="headerlink" href="#install-via-pypi-wheel-in-bare-metal" title="Link to this heading"></a></h2>
<section id="install-oneapi-base-toolkit-packages">
<h3>Install oneAPI Base Toolkit Packages<a class="headerlink" href="#install-oneapi-base-toolkit-packages" title="Link to this heading"></a></h3>
<p>Need to install components of Intel® oneAPI Base Toolkit:</p>
<ul class="simple">
<li><p>Intel® oneAPI DPC++ Compiler</p></li>
<li><p>Intel® oneAPI Math Kernel Library (oneMKL)</p></li>
<li><p>Intel® oneAPI Threading Building Blocks (TBB), dependency of DPC++ Compiler.</p></li>
<li><p>Intel® oneAPI Collective Communications Library (oneCCL), required by Intel® Optimization for Horovod* only</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>wget<span class="w"> </span>https://registrationcenter-download.intel.com/akdlm/IRC_NAS/e6ff8e9c-ee28-47fb-abd7-5c524c983e1c/l_BaseKit_p_2024.2.1.100_offline.sh
<span class="c1"># 3 components are necessary: DPC++/C++ Compiler, DPC++ Libiary and oneMKL</span>
<span class="c1"># if you want to run distributed training with Intel® Optimization for Horovod*, oneCCL is needed too(Intel® oneAPI MPI Library will be installed automatically as its dependency)</span>
$<span class="w"> </span>sudo<span class="w"> </span>sh<span class="w"> </span>l_BaseKit_p_2024.2.1.100_offline.sh
</pre></div>
</div>
<p>For any more details, follow the procedure in https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html.</p>
</section>
<section id="setup-environment-variables">
<h3>Setup environment variables<a class="headerlink" href="#setup-environment-variables" title="Link to this heading"></a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># DPC++ Compiler/oneMKL</span>
<span class="nb">source</span><span class="w"> </span>/path<span class="w"> </span>to<span class="w"> </span>basekit/intel/oneapi/compiler/latest/env/vars.sh
<span class="nb">source</span><span class="w"> </span>/path<span class="w"> </span>to<span class="w"> </span>basekit/intel/oneapi/mkl/latest/env/vars.sh

<span class="c1"># oneCCL (and Intel® oneAPI MPI Library as its dependency), required by Intel® Optimization for Horovod* only</span>
<span class="nb">source</span><span class="w"> </span>/path<span class="w"> </span>to<span class="w"> </span>basekit/intel/oneapi/mpi/latest/env/vars.sh
<span class="nb">source</span><span class="w"> </span>/path<span class="w"> </span>to<span class="w"> </span>basekit/intel/oneapi/ccl/latest/env/vars.sh
</pre></div>
</div>
<p>You may install more components than Intel® Extension for TensorFlow* needs, and if required, <code class="docutils literal notranslate"><span class="pre">setvars.sh</span></code> can be customized to point to a specific directory by using a <a class="reference external" href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-programming-guide/top/oneapi-development-environment-setup/use-the-setvars-script-with-linux-or-macos/use-a-config-file-for-setvars-sh-on-linux-or-macos.html">configuration file</a>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span><span class="w"> </span>/opt/intel/oneapi/setvars.sh<span class="w"> </span>--config<span class="o">=</span><span class="s2">&quot;full/path/to/your/config.txt&quot;</span>
</pre></div>
</div>
</section>
<section id="install-tensorflow">
<h3>Install TensorFlow<a class="headerlink" href="#install-tensorflow" title="Link to this heading"></a></h3>
<p>The Python development and virtual environment setup recommendation by TensorFlow to isolate package installation from the system.</p>
<p>The Intel® Extension for TensorFlow* requires stock TensorFlow, and the version should be == 2.15.0.</p>
<section id="virtual-environment-install">
<h4>Virtual environment install<a class="headerlink" href="#virtual-environment-install" title="Link to this heading"></a></h4>
<p>You can follow the instructions in <a class="reference external" href="https://www.tensorflow.org/install/pip#step-by-step_instructions">stock tensorflow install</a> to activate the virtual environment.</p>
<p>On Linux, it is often necessary to first update pip to a version that supports manylinux2014 wheels.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pip
</pre></div>
</div>
<p>To install in virtual environment, you can run</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span><span class="nv">tensorflow</span><span class="o">==</span><span class="m">2</span>.15.0
</pre></div>
</div>
</section>
<section id="system-environment-install">
<h4>System environment install<a class="headerlink" href="#system-environment-install" title="Link to this heading"></a></h4>
<p>If you prefer install tensorflow in $HOME, please append <code class="docutils literal notranslate"><span class="pre">--user</span></code> to the commands.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--user<span class="w"> </span><span class="nv">tensorflow</span><span class="o">==</span><span class="m">2</span>.15.0
</pre></div>
</div>
<p>And the following system environment install for Intel® Extension for TensorFlow* will also append <code class="docutils literal notranslate"><span class="pre">--user</span></code> to the command.</p>
</section>
</section>
<section id="install-intel-extension-for-tensorflow">
<h3>Install Intel® Extension for TensorFlow*<a class="headerlink" href="#install-intel-extension-for-tensorflow" title="Link to this heading"></a></h3>
<p>To install a XPU version in virtual environment, which depends on Intel GPU drivers and oneAPI BaseKit, you can run</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>intel-extension-for-tensorflow<span class="o">[</span>xpu<span class="o">]</span>
</pre></div>
</div>
<section id="check-the-environment-for-xpu">
<h4>Check the Environment for XPU<a class="headerlink" href="#check-the-environment-for-xpu" title="Link to this heading"></a></h4>
<p>You can follow below the instruction to check environment for XPU.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import intel_extension_for_tensorflow as itex; print(itex.tools.python.env_check.check())&quot;</span>
</pre></div>
</div>
<p>If you have issue to load itex, You can follow below the instruction to check environment for XPU.</p>
<ul class="simple">
<li><p>Option1:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>wget
<span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">path_to_site_packages</span><span class="o">=</span><span class="sb">`</span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import site; print(site.getsitepackages()[0])&quot;</span><span class="sb">`</span>
<span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span>python<span class="w"> </span><span class="si">${</span><span class="nv">path_to_site_packages</span><span class="si">}</span>/intel_extension_for_tensorflow/tools/python/env_check.py
</pre></div>
</div>
<ul class="simple">
<li><p>Option2:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>wget
<span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span>wget<span class="w"> </span>https://raw.githubusercontent.com/intel/intel-extension-for-tensorflow/main/tools/python/env_check.py
<span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span>python<span class="w"> </span>env_check.py
</pre></div>
</div>
</section>
<section id="verify-the-installation">
<h4>Verify the Installation<a class="headerlink" href="#verify-the-installation" title="Link to this heading"></a></h4>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">c</span> <span class="s2">&quot;import intel_extension_for_tensorflow as itex; print(itex.__version__)&quot;</span>
</pre></div>
</div>
<p>Then, you can get the information that GPU backend is loaded successfully  from the console log.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">2023</span><span class="o">-</span><span class="mi">07</span><span class="o">-</span><span class="mi">28</span> <span class="mi">12</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mf">00.217981</span><span class="p">:</span> <span class="n">I</span> <span class="n">itex</span><span class="o">/</span><span class="n">core</span><span class="o">/</span><span class="n">wrapper</span><span class="o">/</span><span class="n">itex_gpu_wrapper</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">35</span><span class="p">]</span> <span class="n">Intel</span> <span class="n">Extension</span> <span class="k">for</span> <span class="n">Tensorflow</span><span class="o">*</span> <span class="n">GPU</span> <span class="n">backend</span> <span class="ow">is</span> <span class="n">loaded</span><span class="o">.</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="xpu-for-cpu-only-platform-deprecated">
<h2>XPU for CPU only platform (Deprecated)<a class="headerlink" href="#xpu-for-cpu-only-platform-deprecated" title="Link to this heading"></a></h2>
<p>Intel® Extension for TensorFlow* XPU package only support GPU platform, which will not work on CPU only platform since v2.15.0.0.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="installation_guide.html" class="btn btn-neutral float-left" title="Installation Guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="install_for_cpu.html" class="btn btn-neutral float-right" title="Intel CPU Software Installation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022-2025 Intel Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   <jinja2.runtime.BlockReference object at 0x7fe9651ae4e0> 
  <p></p><div><a href='https://www.intel.com/content/www/us/en/privacy/intel-cookie-notice.html' data-cookie-notice='true'>Cookies</a> <a href='https://www.intel.com/content/www/us/en/privacy/intel-privacy-notice.html'>| Privacy</a></div>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>