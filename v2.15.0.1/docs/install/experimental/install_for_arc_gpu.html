<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Experimental: Intel® Arc™ A-Series GPU Software Installation &mdash; Intel® Extension for TensorFlow* v2.15.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=439db15d" />

  
<script type="text/javascript">
  // Configure TMS settings
  window.wapProfile = 'profile-microsite'; // This is mapped by WAP authorize value
  window.wapLocalCode = 'us-en'; // Dynamically set per localized site, see mapping table for values
  window.wapSection = "intel-extension-for-tensorflow"; // WAP team will give you a unique section for your site
  window.wapEnv = 'prod'; // environment to be use in Adobe Tags.
  // Load TMS
  (() => {
        let url = 'https://www.intel.com/content/dam/www/global/wap/main/wap-microsite.js';
        let po = document.createElement('script'); po.type = 'text/javascript'; po.async = true; po.src = url;
        let s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  }) ();
</script>

    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            Intel® Extension for TensorFlow*
          </a>
            <div class="version">
              <a href="../../../../versions.html">v2.15.0.1▼</a>
              <p>Click link above to switch version</p>
            </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../get_started.html">Quick Get Started*</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide/infrastructure.html">Infrastructure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide/features.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide/performance.html">Performance Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation_guide.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/README.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide/practice_guide.html">Practice Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../guide/FAQ.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/releases.html">Releases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/contributing.html">Contributing guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../SECURITY.html">Security Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/intel-extension-for-tensorflow">GitHub Repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Intel® Extension for TensorFlow*</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active"><em>Experimental:</em> Intel® Arc™ A-Series GPU Software Installation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/docs/install/experimental/install_for_arc_gpu.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="experimental-intel-arc-a-series-gpu-software-installation">
<h1><em>Experimental:</em> Intel® Arc™ A-Series GPU Software Installation<a class="headerlink" href="#experimental-intel-arc-a-series-gpu-software-installation" title="Link to this heading"></a></h1>
<section id="experimental-release">
<h2><em>Experimental Release</em><a class="headerlink" href="#experimental-release" title="Link to this heading"></a></h2>
<p>The Intel® Extension for TensorFlow* has early <em>experimental only support</em> for Intel® Arc™ A-Series GPUs on Windows Subsystem for Linux 2 with Ubuntu Linux installed and native Ubuntu Linux.</p>
<p>Issues opened for the Intel® Extension for TensorFlow* on Intel® Arc™ A-Series GPUs will be addressed on a best-effort basis, but no guarantee is provided as to when these issues will be fixed.</p>
</section>
<section id="hardware-requirements">
<h2>Hardware Requirements<a class="headerlink" href="#hardware-requirements" title="Link to this heading"></a></h2>
<p>Hardware Platforms with Experimental Only Support:</p>
<ul class="simple">
<li><p>Intel® Arc™ A-Series GPUs</p></li>
</ul>
</section>
<section id="software-requirements">
<h2>Software Requirements<a class="headerlink" href="#software-requirements" title="Link to this heading"></a></h2>
<section id="windows-subsystem-for-linux-2-wsl2">
<h3>Windows Subsystem for Linux 2 (WSL2)<a class="headerlink" href="#windows-subsystem-for-linux-2-wsl2" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>For <a class="reference external" href="https://www.microsoft.com/en-us/windows/get-windows-10">Windows 10</a> or <a class="reference external" href="https://www.microsoft.com/en-us/windows/windows-11">Windows 11</a>:</p>
<ul>
<li><p><a class="reference external" href="https://learn.microsoft.com/en-us/windows/wsl/about">Windows Subystem for Linux 2</a> (WSL2) with Ubuntu 22.04 (64-bit)</p></li>
<li><p>Windows GPU Drivers: <a class="reference external" href="https://www.intel.com/content/www/us/en/download/785597/intel-arc-iris-xe-graphics-windows.html">Intel® Arc™ Graphics Windows Driver 31.0.101.5333</a> or later (installation instructions below)</p></li>
</ul>
</li>
<li><p>For Ubuntu Linux 22.04 within WSL2:</p>
<ul>
<li><p>Linux Runtime Libraries: Intel® Arc™ GPU Drivers <a class="reference external" href="https://dgpu-docs.intel.com/releases/LTS_803.29_20240131.html">803</a> (installation instructions below)</p></li>
<li><p>Intel® oneAPI Base Toolkit 2024.2.1 (installation instructions below)</p></li>
<li><p>TensorFlow 2.15.1</p></li>
<li><p>Python 3.9-3.11</p></li>
<li><p>pip 19.0 or later (requires manylinux2014 support)</p></li>
</ul>
</li>
</ul>
</section>
<section id="native-linux-running-directly-on-hardware">
<h3>Native Linux Running Directly on Hardware<a class="headerlink" href="#native-linux-running-directly-on-hardware" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>Ubuntu 22.04 (64-bit)</p></li>
<li><p>Intel® GPU Drivers for Linux (installation instructions below)</p></li>
<li><p>Intel® Arc™ GPU Drivers <a class="reference external" href="https://dgpu-docs.intel.com/releases/LTS_803.29_20240131.html">803</a></p></li>
<li><p>Intel® oneAPI Base Toolkit 2024.2.1 (installation instructions below)</p></li>
<li><p>TensorFlow 2.15.1</p></li>
<li><p>Python 3.9-3.11</p></li>
<li><p>pip 19.0 or later (requires manylinux2014 support)</p></li>
</ul>
</section>
</section>
<section id="step-by-step-instructions">
<h2>Step-By-Step Instructions<a class="headerlink" href="#step-by-step-instructions" title="Link to this heading"></a></h2>
<section id="install-gpu-drivers">
<h3>1. Install GPU Drivers<a class="headerlink" href="#install-gpu-drivers" title="Link to this heading"></a></h3>
<section id="id1">
<h4>Windows Subsystem for Linux 2 (WSL2)<a class="headerlink" href="#id1" title="Link to this heading"></a></h4>
<p>When using WSL2, the GPU drivers are installed in the Windows OS and runtime components such as <a class="reference external" href="https://github.com/oneapi-src/level-zero">Level-Zero</a> are installed within Linux (in WSL2).</p>
<section id="windows-gpu-drivers">
<h5>Windows GPU Drivers<a class="headerlink" href="#windows-gpu-drivers" title="Link to this heading"></a></h5>
<table border="1" class="docutils">
<thead>
<tr>
<th>OS</th>
<th>Intel GPU</th>
<th>Install Intel GPU Driver</th>
</tr>
</thead>
<tbody>
<tr>
<td>Windows 10, Windows 11</td>
<td>Intel® Arc™ A-Series GPUs</td>
<td><a href="https://www.intel.com/content/www/us/en/download/785597/intel-arc-iris-xe-graphics-windows.html">Intel® Arc™ Graphics Windows Driver 31.0.101.5333</a></td>
</tr>
</tbody>
</table><p>Install the above Intel® Arc™ Graphics Windows DCH Driver in the Windows OS.</p>
</section>
<section id="ubuntu-linux-installed-in-wsl2">
<h5>Ubuntu Linux Installed in WSL2<a class="headerlink" href="#ubuntu-linux-installed-in-wsl2" title="Link to this heading"></a></h5>
<table border="1" class="docutils">
<thead>
<tr>
<th>OS</th>
<th>Intel GPU</th>
<th>Install Intel Compute Runtime Components</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ubuntu 22.04 installed in WSL2</td>
<td>Intel® Arc™ A-Series GPUs</td>
<td>Refer to the instructions below for package installation in Ubuntu 22.04. When installing the Intel® Arc™ A-Series GPU Drivers <a href="https://dgpu-docs.intel.com/releases/LTS_803.29_20240131.html">803</a>, please be sure to append the specific version after components, as is done below.</td>
</tr>
</tbody>
</table><p>The steps to install the runtime components in Ubuntu Linux (within WSL2) are:</p>
<ul>
<li><p>Add the repositories.intel.com/graphics package repository to your Ubuntu installation:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>gpg-agent<span class="w"> </span>wget
wget<span class="w"> </span>-qO<span class="w"> </span>-<span class="w"> </span>https://repositories.intel.com/gpu/intel-graphics.key<span class="w"> </span><span class="p">|</span><span class="w"> </span>
sudo<span class="w"> </span>gpg<span class="w"> </span>--dearmor<span class="w"> </span>--output<span class="w"> </span>/usr/share/keyrings/intel-graphics.gpg
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;deb [arch=amd64 signed-by=/usr/share/keyrings/intel-graphics.gpg] https://repositories.intel.com/gpu/ubuntu jammy/lts/2350 unified&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/apt/sources.list.d/intel-gpu-jammy.list
sudo<span class="w"> </span>apt-get<span class="w"> </span>update
</pre></div>
</div>
</li>
<li><p>Install the necessary runtime packages:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>intel-igc-cm<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>intel-level-zero-gpu<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>intel-opencl-icd<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>level-zero<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>libigc1<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>libigdfcl1<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>libigdgmm12
</pre></div>
</div>
</li>
<li><p>Add the Intel® oneAPI library repositories to your Ubuntu installation:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>-O-<span class="w"> </span>https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>gpg<span class="w"> </span>--dearmor<span class="w"> </span>--output<span class="w"> </span>/usr/share/keyrings/oneapi-archive-keyring.gpg
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;deb [signed-by=/usr/share/keyrings/oneapi-archive-keyring.gpg] https://apt.repos.intel.com/oneapi all main&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/apt/sources.list.d/oneAPI.list
sudo<span class="w"> </span>apt-get<span class="w"> </span>update
</pre></div>
</div>
</li>
<li><p>Install the necessary Intel® oneAPI library packages:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>intel-oneapi-runtime-dpcpp-cpp<span class="w"> </span>intel-oneapi-runtime-mkl
</pre></div>
</div>
</li>
</ul>
<p>The above commands install only runtime libraries for Intel® oneAPI that are used by the Intel® Extension for TensorFlow*.  If you would instead prefer to install the full Intel® oneAPI, see section <a class="reference external" href="#optional-install-full-intel%C2%AE-oneapi">Optional: Install Full Intel® oneAPI Base Toolkit Packages</a>.</p>
</section>
</section>
<section id="id2">
<h4>Native Linux Running Directly on Hardware<a class="headerlink" href="#id2" title="Link to this heading"></a></h4>
<table border="1" class="docutils">
<thead>
<tr>
<th>OS</th>
<th>Intel GPU</th>
<th>Install Intel GPU Driver</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ubuntu 22.04</td>
<td>Intel® Arc™ A-Series GPUs</td>
<td>Refer to the instructions below for package installation in Ubuntu 22.04.</td>
</tr>
</tbody>
</table><p>The steps to install the runtime components in Ubuntu Linux are:</p>
<ul>
<li><p>The Intel® Extension for TensorFlow* requires a specific set of drivers for native Linux.  Please follow the instructions in <a class="reference external" href="https://dgpu-docs.intel.com/driver/installation.html">Installation Guides for Intel Arc GPUs</a>. When installing the Intel® Arc™ A-Series GPU Drivers <a class="reference external" href="https://dgpu-docs.intel.com/releases/LTS_803.29_20240131.html">803</a>, setup the LTS repository and install runtime components.</p></li>
<li><p>Add the repositories.intel.com/graphics package repository to your Ubuntu installation:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>gpg-agent<span class="w"> </span>wget
wget<span class="w"> </span>-qO<span class="w"> </span>-<span class="w"> </span>https://repositories.intel.com/gpu/intel-graphics.key<span class="w"> </span><span class="p">|</span><span class="w"> </span>
sudo<span class="w"> </span>gpg<span class="w"> </span>--dearmor<span class="w"> </span>--output<span class="w"> </span>/usr/share/keyrings/intel-graphics.gpg
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;deb [arch=.html64 signed-by=/usr/share/keyrings/intel-graphics.gpg] https://repositories.intel.com/gpu/ubuntu jammy/lts/2350 unified&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/apt/sources.list.d/intel-gpu-jammy.list
sudo<span class="w"> </span>apt-get<span class="w"> </span>update
</pre></div>
</div>
</li>
<li><p>Install the necessary runtime packages:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>intel-opencl-icd
</pre></div>
</div>
</li>
<li><p>Install the Intel® oneAPI libraries</p>
<ul>
<li><p>Add the Intel® oneAPI library repositories to your Ubuntu installation:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>wget<span class="w"> </span>-O-<span class="w"> </span>https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>gpg<span class="w"> </span>--dearmor<span class="w"> </span>--output<span class="w"> </span>/usr/share/keyrings/oneapi-archive-keyring.gpg
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;deb [signed-by=/usr/share/keyrings/oneapi-archive-keyring.gpg] https://apt.repos.intel.com/oneapi all main&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/apt/sources.list.d/oneAPI.list
sudo<span class="w"> </span>apt-get<span class="w"> </span>update
</pre></div>
</div>
<ul class="simple">
<li><p>Install the necessary Intel® oneAPI library packages:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>intel-oneapi-runtime-dpcpp-cpp<span class="w"> </span>intel-oneapi-runtime-mkl
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
<p>The above commands install only runtime libraries for Intel® oneAPI that are used by the Intel® Extension for TensorFlow*.  If you would instead prefer to install the full Intel® oneAPI, see section <a class="reference external" href="#optional-install-full-intel%C2%AE-oneapi">Optional: Install Full Intel® oneAPI Base Toolkit Packages</a>.</p>
</section>
</section>
<section id="install-tensorflow-via-pypi-wheel-in-linux">
<h3>2. Install TensorFlow* via PyPI Wheel in Linux<a class="headerlink" href="#install-tensorflow-via-pypi-wheel-in-linux" title="Link to this heading"></a></h3>
<p>The following steps can be used to install the TensorFlow framework and other necessary software in Ubuntu Linux running native (installed directly on hardware) or running within Windows Subsystem for Linux 2.</p>
<section id="install-tensorflow">
<h4>Install TensorFlow<a class="headerlink" href="#install-tensorflow" title="Link to this heading"></a></h4>
<p>The Python development and virtual environment setup recommendation by TensorFlow is to isolate package installation from the system.</p>
<p>The Intel® Extension for TensorFlow* requires stock TensorFlow, and the version should be == 2.15.1.</p>
<ul class="simple">
<li></li>
</ul>
<section id="virtual-environment-install">
<h5>Virtual environment install<a class="headerlink" href="#virtual-environment-install" title="Link to this heading"></a></h5>
<p>You can follow the instructions in <a class="reference external" href="https://www.tensorflow.org/install/pip#step-by-step_instructions">stock tensorflow install</a> to activate the virtual environment.</p>
<p>On Linux, it is often necessary to first update pip to a version that supports manylinux2014 wheels.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pip
</pre></div>
</div>
<p>To install in virtual environment, you can run</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span><span class="s1">&#39;tensorflow==2.15.1&#39;</span>
</pre></div>
</div>
</section>
<li></li>
<section id="system-environment-install">
<h5>System environment install<a class="headerlink" href="#system-environment-install" title="Link to this heading"></a></h5>
<p>If you prefer to install tensorflow in $HOME, append <code class="docutils literal notranslate"><span class="pre">--user</span></code> to the commands.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--user<span class="w"> </span><span class="s1">&#39;tensorflow==2.15.1&#39;</span>
</pre></div>
</div>
<p>And the following system environment install for Intel® Extension for TensorFlow* will also append <code class="docutils literal notranslate"><span class="pre">--user</span></code> to the commands.</p>
</section>
</section>
</section>
<section id="install-intel-extension-for-tensorflow">
<h3>3. Install Intel® Extension for TensorFlow*<a class="headerlink" href="#install-intel-extension-for-tensorflow" title="Link to this heading"></a></h3>
<p>To install an XPU version in virtual environment, which depends on Intel GPU drivers and oneAPI BaseKit, you can run</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>intel-extension-for-tensorflow<span class="o">[</span>xpu<span class="o">]</span>
</pre></div>
</div>
<p>Check the environment for XPU:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="nv">path_to_site_packages</span><span class="o">=</span><span class="sb">`</span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import site; print(site.getsitepackages()[0])&quot;</span><span class="sb">`</span>
<span class="o">(</span>tf<span class="o">)</span>$<span class="w"> </span>bash<span class="w"> </span><span class="si">${</span><span class="nv">path_to_site_packages</span><span class="si">}</span>/intel_extension_for_tensorflow/tools/env_check.sh
</pre></div>
</div>
</section>
<section id="verify-the-installation">
<h3>4. Verify the Installation<a class="headerlink" href="#verify-the-installation" title="Link to this heading"></a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">c</span> <span class="s2">&quot;import intel_extension_for_tensorflow as itex; print(itex.__version__)&quot;</span>
</pre></div>
</div>
<p>You can also run a <a class="reference external" href="../../../examples/quick_example.html">quick_example</a> to verify the installation.</p>
</section>
<section id="optional-install-full-intel-oneapi">
<h3>Optional: Install Full Intel® oneAPI<a class="headerlink" href="#optional-install-full-intel-oneapi" title="Link to this heading"></a></h3>
<p>If you prefer to have access to full Intel® oneAPI, you need to install at least the following:</p>
<ul class="simple">
<li><p>Intel® oneAPI DPC++ Compiler</p></li>
<li><p>Intel® oneAPI Math Kernel Library (oneMKL)</p></li>
</ul>
<p>Download and install the verified DPC++ compiler and oneMKL in Ubuntu 22.04.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>wget<span class="w"> </span>https://registrationcenter-download.intel.com/akdlm/IRC_NAS/e6ff8e9c-ee28-47fb-abd7-5c524c983e1c/l_BaseKit_p_2024.2.1.100_offline.sh
<span class="c1"># 3 components are necessary: DPC++/C++ Compiler, DPC++ Library and oneMKL</span>
<span class="c1"># if you want to run distributed training with Intel® Optimization for Horovod*, oneCCL is needed too (Intel® oneAPI MPI Library will be installed automatically as its dependency)</span>
$<span class="w"> </span>sudo<span class="w"> </span>sh<span class="w"> </span>l_BaseKit_p_2024.2.1.100_offline.sh
</pre></div>
</div>
<p>For any more details, please follow the procedure in <a class="reference external" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html">Intel® oneAPI Base Toolkit</a>.</p>
<section id="setup-environment-variables">
<h4>Setup environment variables<a class="headerlink" href="#setup-environment-variables" title="Link to this heading"></a></h4>
<p>When using the full Intel® oneAPI Base Toolkit, you will need to set up necessary environment variables with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span><span class="w"> </span>/opt/intel/oneapi/setvars.sh
</pre></div>
</div>
<p>You may install more components than Intel® Extension for TensorFlow* needs, and if required, <code class="docutils literal notranslate"><span class="pre">setvars.sh</span></code> can be customized to point to a specific directory by using a <a class="reference external" href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-programming-guide/top/oneapi-development-environment-setup/use-the-setvars-script-with-linux-or-macos/use-a-config-file-for-setvars-sh-on-linux-or-macos.html">configuration file</a>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span><span class="w"> </span>/opt/intel/oneapi/setvars.sh<span class="w"> </span>--config<span class="o">=</span><span class="s2">&quot;full/path/to/your/config.txt&quot;</span>
</pre></div>
</div>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022-2024 Intel Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   <jinja2.runtime.BlockReference object at 0x7f93ab534160> 
  <p></p><div><a href='https://www.intel.com/content/www/us/en/privacy/intel-cookie-notice.html' data-cookie-notice='true'>Cookies</a> <a href='https://www.intel.com/content/www/us/en/privacy/intel-privacy-notice.html'>| Privacy</a></div>


</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
