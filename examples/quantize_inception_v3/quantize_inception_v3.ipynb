{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7c3286e",
   "metadata": {},
   "source": [
    "# Quantize InceptionV3 by Intel® Extenstion for Tensorflow* on Intel® Xeon®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f290e4",
   "metadata": {},
   "source": [
    "## introduction\n",
    "\n",
    "\n",
    "The example shows an End-To-End pipeline:\n",
    "\n",
    "1. Train a InceptionV3 model with a flower photo dataset by transfer learning.\n",
    "\n",
    "2. Execute the calibration by Intel® Neural Compressor.\n",
    "\n",
    "3. Quantize and accelerate the inference by Intel® Extenstion for Tensorflow* for CPU.\n",
    "\n",
    "This example can be executed on Intel® CPU supports Intel® AVX-512 Vector Neural Network Instructions (VNNI) or Intel® Advanced Matrix Extensions (AMX). There will be more performance improvement on Intel® CPU with AMX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0c7db5",
   "metadata": {},
   "source": [
    "## Import Depended Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import neural_compressor as inc\n",
    "print(\"neural_compressor version {}, need >=2.0\".format(inc.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"tensorflow {}, need >=2.10.0\".format(tf.__version__))\n",
    "\n",
    "import intel_extension_for_tensorflow as itex\n",
    "print(\"intel_extension_for_tensorflow version {}, need >=1.1.0\".format(itex.__version__))\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635c8ee5",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We use a dataset of several thousand flowers photos. The flowers dataset contains five sub-folders for five classes:\n",
    "\n",
    "```\n",
    "flowers_photos/\n",
    "  daisy/\n",
    "  dandelion/\n",
    "  roses/\n",
    "  sunflowers/\n",
    "  tulips/\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36037339",
   "metadata": {},
   "source": [
    "1. Download the dataset from internet and extract it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d82ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -r -nc -P ./ http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "!tar -zxvf flower_photos.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab7dba7",
   "metadata": {},
   "source": [
    "2. Create dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50c4d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH=224\n",
    "HEIGHT=224\n",
    "BATCH_SIZE=32\n",
    "\n",
    "dataset_folder = './flower_photos/'\n",
    "\n",
    "image_size = (WIDTH, HEIGHT)\n",
    "\n",
    "\n",
    "def process(image,label):\n",
    "    image = tf.cast(image/255.0 ,tf.float32)\n",
    "    return image, label\n",
    "\n",
    "train_dataset, val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_folder,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=100,\n",
    "    image_size=image_size,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode= \"categorical\"\n",
    ")\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "class_num = len(class_names)\n",
    "print(\"Class Num={}\".format(class_num))\n",
    "\n",
    "train_dataset = train_dataset.map(process)\n",
    "val_dataset = val_dataset.map(process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3618de37",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a68d54",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "\n",
    "We will download a pre-trained InceptionV3 FP32 model by Keras API.\n",
    "\n",
    "We disable the training capability of the pre-trained FP32 model part, and add 1 GlobalAveragePooling2D layer and 3 Dense layers. The final tf.keras.layers.Dense is with class number of the data and activation function **softmax**.\n",
    "\n",
    "During the training, only the added layers are training. With the feature extractor function of pre-trained layers, it's easy to train the model in short time with the custom dataset in short time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30fd6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(w, h, class_num):    \n",
    "    base_model=tf.keras.applications.InceptionV3(weights='imagenet',include_top=False)\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)   \n",
    "    predictions = tf.keras.layers.Dense(class_num, activation='softmax')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # show the latest 10 layers' traninable\n",
    "    for layer in model.layers[-10:]:\n",
    "        print(\"{}\\t{}\".format(layer.trainable, layer.name,))\n",
    "\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = build_model(WIDTH, HEIGHT, class_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca7e14",
   "metadata": {},
   "source": [
    "### Training Model\n",
    "\n",
    "Train the model with 2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7628e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs=1):\n",
    "    hist = model.fit(train_dataset, epochs = epochs, validation_data = val_dataset)\n",
    "    result = model.evaluate(val_dataset)\n",
    "    \n",
    "epochs=2\n",
    "train_model(model, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f509f4",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_path):    \n",
    "    model.save(model_path)\n",
    "    print(\"Save model to {}\".format(model_path))\n",
    "    \n",
    "model_fp32_path=\"model_keras.fp32\"\n",
    "save_model(model, model_fp32_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f042e32",
   "metadata": {},
   "source": [
    "## Quantize Model by Intel® Neural Compressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa967612",
   "metadata": {},
   "source": [
    "### YAML File\n",
    "\n",
    "To support quantization by Intel® Extenstion for Tensorflow* with oneDNN Graph, we need to set the **framework** as **tensorflow_itex**.\n",
    "\n",
    "It's only special setting for Intel® Extenstion for Tensorflow*. Other configuration is same as legacy.\n",
    "\n",
    "The mandatory items are framework, evalution, accuracy_criterion and exist_policy.\n",
    "\n",
    "The tuning target is the accuracy loss percentage is thess than **1%**. We could edit it in Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b3c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Code('inceptionv3.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283be9ad",
   "metadata": {},
   "source": [
    "### Custom Dataset\n",
    "\n",
    "The custom dataset class must provide two methods: `__len__()` and `__getitem__()`.\n",
    "\n",
    "In this case, use the integrated metric function in this tool. So the dataset format must follow the requirement of default metric function. So the label format is class index, instead of categorical vector (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b276ba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image,label):\n",
    "    image = tf.cast(image/255.0, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self):\n",
    "        # load dataset in memory and format as list [(image, lable), (image, label)]\n",
    "        dataset_folder = 'flower_photos/'\n",
    "        image_size = (224, 224)\n",
    "\n",
    "        train_dataset, val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            dataset_folder,\n",
    "            validation_split=0.2,\n",
    "            subset=\"both\",\n",
    "            seed=100,\n",
    "            image_size=image_size,\n",
    "            batch_size=1\n",
    "         )\n",
    "\n",
    "        class_names = train_dataset.class_names\n",
    "        class_num = len(class_names)\n",
    "\n",
    "        self.train_dataset = list(train_dataset.map(process))\n",
    "        self.train_dataset = [(tf.reshape(images, [224, 224, 3]), labels) for images, labels in self.train_dataset]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # return (image, label) by index       \n",
    "        return self.train_dataset[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # return dataset size as integer\n",
    "        return len(self.train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb526f9a",
   "metadata": {},
   "source": [
    "### Quantize by Intel® Neural Compressor API\n",
    "\n",
    "Create the dataloader by custom data defined above. Call Intel® Neural Compressor API to quantize the FP32 model.\n",
    "\n",
    "The executing time depends on the size of dataset and accuracy target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18371fad",
   "metadata": {},
   "source": [
    "#### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fcba50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from neural_compressor.experimental import Quantization, common\n",    
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "\n",
    "\n",
    "infer_config = tf.compat.v1.ConfigProto()\n",
    "infer_config.graph_options.rewrite_options.constant_folding = rewriter_config_pb2.RewriterConfig.OFF\n",
    "session = tf.compat.v1.Session(config=infer_config)\n",
    "tf.compat.v1.keras.backend.set_session(session)\n",
    "\n",
    "def auto_tune(input_graph_path, yaml_config, batch_size, int8_pb_file):\n",
    "    quantizer = Quantization(yaml_config)\n",
    "    dataset = Dataset()\n",
    "    quantizer.calib_dataloader = common.DataLoader(dataset, batch_size=batch_size)\n",
    "    quantizer.eval_dataloader = common.DataLoader(dataset, batch_size=batch_size)\n",
    "    quantizer.model = common.Model(input_graph_path)\n",
    "    q_model = quantizer.fit()\n",
    "\n",
    "    return q_model\n",
    "\n",
    "\n",
    "yaml_file = \"inceptionv3.yaml\"\n",
    "batch_size = 32\n",
    "model_fp32_path=\"model_keras.fp32\"\n",
    "int8_pb_file = \"model_pb.int8\"\n",
    "q_model = auto_tune(model_fp32_path, yaml_file, batch_size, int8_pb_file)\n",
    "q_model.save(int8_pb_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d91ea",
   "metadata": {},
   "source": [
    "## Test the Performance & Accuracy\n",
    "\n",
    "We use same script to test the perfomrance and accuracy of the FP32 and INT8 models.\n",
    "\n",
    "Use 4 CPU cores to test process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb288d5",
   "metadata": {},
   "source": [
    "### Execute to Quantizae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85989cb",
   "metadata": {},
   "source": [
    "#### Test FP32 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84652afe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!source env_itex/bin/activate && numactl -C 0-3 python profiling_inc.py --input-graph=./model_keras.fp32 --omp-num-threads=4 --num-inter-threads=1 --num-intra-threads=4 --index=32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bb2513",
   "metadata": {},
   "source": [
    "#### Test INT8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea84db4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!source env_itex/bin/activate && numactl -C 0-3 python profiling_inc.py --input-graph=./model_pb.int8 --omp-num-threads=4 --num-inter-threads=1 --num-intra-threads=4 --index=8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c83895",
   "metadata": {},
   "source": [
    "### Compare the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f93cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python compare_perf.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ce0f97",
   "metadata": {},
   "source": [
    "Show result by graphic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e47d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "listOfImageNames = ['fp32_int8_aboslute.png',\n",
    "                    'fp32_int8_times.png']\n",
    "\n",
    "for imageName in listOfImageNames:\n",
    "    display(Image(filename=imageName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963efbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itex_3.7",
   "language": "python",
   "name": "itex_3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
